{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2O1Z9tyLXodJYTnao2iDu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VISHAL-099/Python.ipynb/blob/main/Face_recognition_with_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Install Libraries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XqkD0RGUNawo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45M77HAhMzof",
        "outputId": "514f1ea1-f0ff-4584-c0f1-344053382e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.3)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.1)\n"
          ]
        }
      ],
      "source": [
        "#The face_recognition library, created and maintained by Adam Geitgey,\n",
        "# wraps around dlib facial recognition functionality.\n",
        "!pip install face_recognition\n",
        "\n",
        "# dlib is a modern C++ toolkit containing machine learning algorithms and\n",
        "# tools for creating complex software in C++ to solve real-world problems.\n",
        "!pip install dlib  #==19.18\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition   ##Detecting and recogniting faces\n",
        "import cv2     ## intracting with images\n",
        "import os       ## For Reading the file name\n",
        "from google.colab.patches import cv2_imshow ## we are importing cv2_imshow from google.colab.patches because google colab doesn't support cv2.imshow() funciton.\n",
        "import numpy as np\n",
        "import imutils\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode"
      ],
      "metadata": {
        "id": "Qd6hHG1jM8pf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "e809b2e7-8465-4de9-9807-73acd6619ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d4bcc800864e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m   \u001b[0;31m##Detecting and recogniting faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m     \u001b[0;31m## intracting with images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m       \u001b[0;31m## For Reading the file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m \u001b[0;31m## we are importing cv2_imshow from google.colab.patches because google colab doesn't support cv2.imshow() funciton.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-855jkqkk/dlib_c3d5b4810ccb4e2caf8f5d19b91dea0c/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = '/content/Imagedataset/vishal.5.5.jpg'\n",
        "url1 = '/content/Imagedataset/vikas.6.2.jpeg'\n",
        "img_bgr = face_recognition.load_image_file(url)\n",
        "img_rgb = cv2.cvtColor(img_bgr,cv2.COLOR_BGR2RGB)\n",
        "#cv2_imshow( img_bgr)\n",
        "cv2_imshow( img_rgb)"
      ],
      "metadata": {
        "id": "PMPf8QxnM8sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#----------Finding face Location for drawing bounding boxes-------\n",
        "face = face_recognition.face_locations(img_rgb)[0]\n",
        "(top,right,bottom,left) = face\n",
        "print (face)"
      ],
      "metadata": {
        "id": "xorBImBNM8ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy = img_rgb.copy() # make copy of original image"
      ],
      "metadata": {
        "id": "tKN9zcltM8ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------Drawing the Rectangle-------------------------\n",
        "cv2.rectangle(copy, (left,top),(right,bottom),(255,255,100),2)\n",
        "cv2_imshow(copy) # print rectangle on copy image"
      ],
      "metadata": {
        "id": "2riyihD8M81v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--Converting image into encodings\n",
        "train_encode = face_recognition.face_encodings(img_rgb)[0]"
      ],
      "metadata": {
        "id": "0oYM2499KfXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( train_encode)"
      ],
      "metadata": {
        "id": "JyKl8cIhKfVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "vfX48qk4KqYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url ='/indervishalvikas.jpg'\n",
        "#load image \n",
        "img1 = face_recognition.load_image_file(url)\n",
        "#covert image to RGB\n",
        "img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)\n",
        "#------to find the face location\n",
        "#find face_locations  - topleft cordinate and botton right cordinate\n",
        "face = face_recognition.face_locations(img1)[0]\n",
        "(top,right,bottom,left) = face\n",
        "\n",
        "copy = img1.copy() # make copy of original image\n",
        "#-------------------Drawing the Rectangle-------------------------\n",
        "cv2.rectangle(copy, (left,top),(right,bottom),(255,255,100),2) \n",
        "cv2_imshow(copy)"
      ],
      "metadata": {
        "id": "m9H2sZnDKfSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url ='/indervishalvikas.jpg'\n",
        "# load image \n",
        "img1 = face_recognition.load_image_file(url)\n",
        "\n",
        "# convert to RGB \n",
        "img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# find the face location\n",
        "faces = face_recognition.face_locations(img1)\n",
        "#print (faces)\n",
        "copy = img1.copy() # make copy of original image\n",
        "print ('Faces detected  ' + str(len(faces)))\n",
        "\n",
        "for face in faces:\n",
        "  top,right,bottom,left = face\n",
        "  cv2.rectangle(copy, (left,top),(right,bottom),(255,255,100),2)\n",
        "\n",
        "cv2_imshow(copy)"
      ],
      "metadata": {
        "id": "2MHw7LZfKfQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train And Test"
      ],
      "metadata": {
        "id": "VHlI2wS1Mde6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train faces\n"
      ],
      "metadata": {
        "id": "XxCcm6LcOYDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a sample picture and learn how to recognize it.\n",
        "image1         = face_recognition.load_image_file(\"/content/Imagedataset/vishal.5.5.jpg\")\n",
        "image1_face_encoding = face_recognition.face_encodings(image1)[0]\n",
        "\n",
        "# Load a second sample picture and learn how to recognize it.\n",
        "image2          = face_recognition.load_image_file(\"/content/Imagedataset/vikas.6.0.jpeg\")\n",
        "image2_face_encoding  = face_recognition.face_encodings(image2)[0]\n",
        "\n",
        "# Load a third sample picture and learn how to recognize it.\n",
        "image3          = face_recognition.load_image_file(\"/content/Imagedataset/inder.7.5.jpg\")\n",
        "image3_face_encoding  = face_recognition.face_encodings(image3)[0]"
      ],
      "metadata": {
        "id": "DMVtFZ5DKfNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create arrays of known face encodings and their names\n",
        "known_face_encodings = [\n",
        "    image1_face_encoding,\n",
        "    image2_face_encoding,\n",
        "    image3_face_encoding\n",
        "]\n",
        "known_face_names = [\n",
        "    \"vishal\",\n",
        "    \"vikas\",\n",
        "    \"inder\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "25A5cPK6OAQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test images"
      ],
      "metadata": {
        "id": "HckNejZCOgDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = '/indervishalvikas.jpg'\n",
        "\n",
        "img1 = face_recognition.load_image_file(url)\n",
        "# convert to RGB \n",
        "img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)\n",
        "# Find all the faces and face encodings in the current frame of video\n",
        "face_locations = face_recognition.face_locations(img1)\n",
        "face_encodings = face_recognition.face_encodings(img1, face_locations)\n",
        "cv2_imshow(img1)\n",
        "print (len(face_locations), face_locations)"
      ],
      "metadata": {
        "id": "If7NAtp1KfI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy = img1.copy() # make copy of original image\n",
        "\n",
        "for face in face_locations :\n",
        "  top,right,bottom,left = face\n",
        "  cv2.rectangle(copy, (left,top),(right,bottom),(255,255,100),2)\n",
        "\n",
        "cv2_imshow(copy)\n",
        "# #font = cv2.FONT_HERSHEY_DUPLEX\n",
        "# #cv2.putText(copy, \"Unknown\", (left , bottom), font, 1.0, (255, 255, 255),1)\n",
        "\n",
        "matches = face_recognition.compare_faces(known_face_encodings,face_encodings[0])\n",
        "print(matches)\n",
        "matches = face_recognition.compare_faces(known_face_encodings,face_encodings[1])\n",
        "print(matches)\n",
        "\n",
        "for i in range( len(matches)) : \n",
        "  if matches[i] == True : \n",
        "    print (i, known_face_names[i])"
      ],
      "metadata": {
        "id": "4HzW-fQLKfGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# known_face_encodings - is the list created from the trained face encoding\n",
        "# face_encodings needs to be compared/searched in the list  known_face_encodings\n",
        "copy = img1.copy()\n",
        "font = cv2.FONT_HERSHEY_DUPLEX\n",
        "for oneface in range(len(face_encodings) ):\n",
        "  # draw box around face \n",
        "  top,right,bottom,left = face_locations[oneface]\n",
        "  cv2.rectangle(copy, (left,top),(right,bottom),(255,255,100),2)\n",
        "  # compare and get name /print \n",
        "  matches = face_recognition.compare_faces(known_face_encodings,face_encodings[oneface])\n",
        "  if True in matches :\n",
        "    for i in range ( len(matches)):\n",
        "      if matches[i]== True : \n",
        "        #print (known_face_names[i])\n",
        "        cv2.putText(copy,known_face_names[i], (left , bottom), font, 1.0, (255, 255, 255),1)\n",
        "  else: \n",
        "    cv2.putText(copy, \"Unknown\", (left , bottom), font, 1.0, (255, 255, 255),1)\n",
        "    #print (\"unknown\")\n",
        "\n",
        "cv2_imshow(copy)"
      ],
      "metadata": {
        "id": "IQqAl1jjO6ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_names = []\n",
        "for face_encoding in face_encodings:\n",
        "    # See if the face is a match for the known face(s)\n",
        "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "    name = \"Unknown\"\n",
        "\n",
        "    # # If a match was found in known_face_encodings, just use the first one.\n",
        "    if True in matches:\n",
        "        first_match_index = matches.index(True)\n",
        "        name = known_face_names[first_match_index]\n",
        "    # Or instead, use the known face with the smallest distance to the new face\n",
        "    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "    best_match_index = np.argmin(face_distances)\n",
        "    if matches[best_match_index]:\n",
        "        name = known_face_names[best_match_index]\n",
        "\n",
        "    face_names.append(name)\n",
        "    \n",
        "print (face_names )"
      ],
      "metadata": {
        "id": "KeUhsT7OO6tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results\n",
        "for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
        "    # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
        "    top *= 4\n",
        "    right *= 4\n",
        "    bottom *= 4\n",
        "    left *= 4\n",
        "\n",
        "    # Draw a box around the face\n",
        "    cv2.rectangle(img1, (left, top), (right, bottom), (0, 0, 255), 2)\n",
        "\n",
        "    # Draw a label with a name below the face\n",
        "    cv2.rectangle(img1, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
        "    font = cv2.FONT_HERSHEY_DUPLEX\n",
        "    cv2.putText(img1, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "#show the image with names \n",
        "cv2_imshow(img1)  "
      ],
      "metadata": {
        "id": "4m5aE1hcO6q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dgwLwXREQnnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xQWpFGFcQnkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-8CXnvrMQnge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z1mGS8iBQndx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lj9L2r31Qna_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting Webcam"
      ],
      "metadata": {
        "id": "xFQcu0UJQbwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libraries"
      ],
      "metadata": {
        "id": "XOzFucfGR_Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition   ##Detecting and recogniting faces\n",
        "import cv2     ## intracting with images\n",
        "import os       ## For Reading the file name\n",
        "from google.colab.patches import cv2_imshow ## we are importing cv2_imshow from google.colab.patches because google colab doesn't support cv2.imshow() funciton.\n",
        "import numpy as np\n",
        "import imutils\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode"
      ],
      "metadata": {
        "id": "P7lvVhNTO6oQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "f7f225f9-08fc-48e4-9bc6-1bcb885c544c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-d4bcc800864e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m   \u001b[0;31m##Detecting and recogniting faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m     \u001b[0;31m## intracting with images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m       \u001b[0;31m## For Reading the file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m \u001b[0;31m## we are importing cv2_imshow from google.colab.patches because google colab doesn't support cv2.imshow() funciton.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-855jkqkk/dlib_c3d5b4810ccb4e2caf8f5d19b91dea0c/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "web cam"
      ],
      "metadata": {
        "id": "Neoqcv5QSEow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "PB6y7LMrO6lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def faceRecognition (imgFileName):\n",
        "  img1 = face_recognition.load_image_file(imgFileName)\n",
        "  # convert to RGB \n",
        "  img1 = cv2.cvtColor(img1,cv2.COLOR_BGR2RGB)\n",
        "  # Find all the faces and face encodings in the current frame of video\n",
        "  face_locations = face_recognition.face_locations(img1)\n",
        "  face_encodings = face_recognition.face_encodings(img1, face_locations)\n",
        "\n",
        "  copy = img1.copy()\n",
        "  font = cv2.FONT_HERSHEY_DUPLEX\n",
        "  for oneface in range(len(face_encodings) ):\n",
        "    # draw box around face \n",
        "    top,right,bottom,left = face_locations[oneface]\n",
        "    cv2.rectangle(copy, (left,top),(right,bottom),(255,255,100),2)\n",
        "    # compare and get name /print \n",
        "    matches = face_recognition.compare_faces(known_face_encodings,face_encodings[oneface])\n",
        "    if True in matches :\n",
        "      for i in range ( len(matches)):\n",
        "        if matches[i]== True : \n",
        "          #print (known_face_names[i])\n",
        "          cv2.putText(copy,known_face_names[i], (left , bottom), font, 1.0, (255, 255, 255),1)\n",
        "    else: \n",
        "      cv2.putText(copy, \"Unknown\", (left , bottom), font, 1.0, (255, 255, 255),1)\n",
        "      #print (\"unknown\")\n",
        "\n",
        "  cv2_imshow(copy)"
      ],
      "metadata": {
        "id": "A5icUCnCQmXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " test the complete system & Capture IMG"
      ],
      "metadata": {
        "id": "V_f7tidyRqBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_file = take_photo()"
      ],
      "metadata": {
        "id": "XisiehY5O6io",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "5f21acc6-710a-4c06-86b7-0973d95a0409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-027c73c59822>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-39896a1c9887>\u001b[0m in \u001b[0;36mtake_photo\u001b[0;34m(filename, quality)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtake_photo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'photo.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   js = Javascript('''\n\u001b[0m\u001b[1;32m      3\u001b[0m     async function takePhoto(quality) {\n\u001b[1;32m      4\u001b[0m       \u001b[0mconst\u001b[0m \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mconst\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'button'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Javascript' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recognition Method"
      ],
      "metadata": {
        "id": "eR7_iSoMRu7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faceRecognition(image_file)"
      ],
      "metadata": {
        "id": "wnvK1KVpQ8_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PuWqhRzYQ873"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2sVPbTlQ8ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "heNPsEGUQ8r4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}